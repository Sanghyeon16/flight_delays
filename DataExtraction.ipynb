{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DSC2020\n",
    "----\n",
    "Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250845\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "'''\n",
    "Data reduction\n",
    "'''\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def makeHeadfile(rawFileName='oneHotData.csv', newFileName='FlightDelays_heads.csv', keepingRate=10, merge=False):\n",
    "    data = []\n",
    "    with open(rawFileName) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            if line_count==0:\n",
    "                data.append(row)\n",
    "            line_count += 1\n",
    "            if line_count >= keepingRate:\n",
    "                data.append(row)\n",
    "                line_count = 1\n",
    "    print(len(data))\n",
    "    with open(newFileName, mode='w', newline='') as head_file:\n",
    "        head_writer = csv.writer(head_file, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "        head_writer.writerows(data)\n",
    "    \n",
    "    return data[0]\n",
    "\n",
    "\n",
    "keepingRate = 15\n",
    "raw_col = makeHeadfile(newFileName='oneHot_sample.csv',keepingRate=keepingRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "'''\n",
    "data merging functions\n",
    "'''\n",
    "import pandas as pd\n",
    "import csv\n",
    "\n",
    "\n",
    "# df = Original FlightDelays data + Q3 data \n",
    "def mergeQ3(baseFileName, q3FileName):\n",
    "    data = pd.read_csv(baseFileName)\n",
    "    \n",
    "    q3 = pd.read_csv(q3FileName)\n",
    "    q3 = q3.rename(columns={\"CANCELLED\": \"CANCELED\"})\n",
    "    \n",
    "    result = data.append(q3, sort=False)\n",
    "    result = result.drop(columns=['Unnamed: 0', 'ORIGIN_CITY', 'DEST_CITY_NAME'])\n",
    "    df = result.drop(result[result['CANCELED'] == 1].index)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# df = Original FlightDelays data + Q3 data + Market share info data\n",
    "def mergeMarketShare(data, addingFileName):\n",
    "    \n",
    "    market = pd.read_csv(addingFileName)\n",
    "    market = market.rename(columns={\"Origin\":\"ORIGIN\", \"Dest\":\"DEST\"})\n",
    "    newColName = ['ORIGIN', 'DEST','nsmiles', 'fare', 'carrier_lg', 'large_ms', 'fare_lg', 'carrier_low', 'lf_ms', 'fare_low']\n",
    "    data = pd.merge(data,\n",
    "                     market[newColName],\n",
    "                     on=['ORIGIN', 'DEST'])\n",
    "    \n",
    "    \n",
    "    data = data.sample(frac=1)\n",
    "    return data\n",
    "\n",
    "def mergeHubs(data, hubsFileName):\n",
    "    \n",
    "    #make hub lists of list\n",
    "    def loadHub(hubsFileName):\n",
    "        hub = []\n",
    "        with open(hubsFileName) as csv_file:\n",
    "            hubs = csv.reader(csv_file, delimiter=',')\n",
    "            t = 0\n",
    "            for row in hubs:            \n",
    "                if t != 0:\n",
    "                    hub.append(row[0:3])\n",
    "                t = 1\n",
    "        return hub\n",
    "    \n",
    "    #compare condition and set hub values\n",
    "    def hubmap(row):\n",
    "        if row['CARRIER'] == 'AA':\n",
    "            if row['DEST'] in carrierdict['AA']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == 'UA':\n",
    "            if row['DEST'] in carrierdict['UA']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == 'DL':\n",
    "            if row['DEST'] in carrierdict['DL']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == 'WN':\n",
    "            if row['DEST'] in carrierdict['WN']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == 'B6':\n",
    "            if row['DEST'] in carrierdict['B6']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == 'AS':\n",
    "            if row['DEST'] in carrierdict['AS']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif row['CARRIER'] == '9E':\n",
    "            if row['DEST'] in carrierdict['9E']:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    hub = loadHub(hubsFileName)\n",
    "    hubs = pd.DataFrame(hub, columns=['CARRIER', 'ORIGIN', 'HUBS'])\n",
    "    hubs['DEST'] = hubs['ORIGIN']\n",
    "    \n",
    "    Carriers = hubs['CARRIER'].unique()\n",
    "    carrierdict = {}\n",
    "    for c in Carriers:\n",
    "        tmp = hubs.loc[hubs['CARRIER'] == c]\n",
    "        list0 = tmp['DEST']\n",
    "        carrierdict[c] = list0.values.tolist()      \n",
    "    \n",
    "    data['HUBS'] = data.apply (lambda row: hubmap(row), axis=1)\n",
    "    \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseFileName = 'FlightDelays_sample.csv'\n",
    "q3FileName = 'FlightDelays_2019Q3_addfinancial.csv'\n",
    "addingFileName = 'AirFares.csv'\n",
    "hubsFileName = 'Hubs.csv'\n",
    "\n",
    "data = mergeQ3(baseFileName, q3FileName)\n",
    "data = mergeMarketShare(data, addingFileName)\n",
    "data = mergeHubs(data, hubsFileName)\n",
    "data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "save data with specific attributes to reduce data size\n",
    "'''\n",
    "\n",
    "inputX = ['YEAR', 'QUARTER', 'MONTH','DAY_OF_MONTH','DAY_OF_WEEK','CARRIER','FL_NUM','Route','ORIGIN', 'DEST','DEST_STATE',\n",
    "       'CRS_DEP_TIME', 'CRS_ARR_TIME', 'CRS_ELAPSED_TIME', 'DISTANCE', 'PASSENGERS', 'EMPFTE', 'NET_INCOME',\n",
    "        'OP_REVENUES', 'fare', 'carrier_lg', 'large_ms', 'fare_lg','HUBS', 'ARR_DELAY_GROUP']\n",
    "\n",
    "data = data[inputX]\n",
    "data.to_csv(r'ourAtt.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
